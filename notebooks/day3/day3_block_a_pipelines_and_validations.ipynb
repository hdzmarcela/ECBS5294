{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2332f652",
   "metadata": {},
   "source": [
    "# Day 3, Block A: Data Pipelines & Real-World Validation\n",
    "\n",
    "**Duration:** 100 minutes (13:30â€“15:10)\n",
    "**Course:** ECBS5294 - Introduction to Data Science: Working with Data\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this session, you will be able to:\n",
    "\n",
    "1. Explain the **bronze â†’ silver â†’ gold** pipeline pattern and why it matters\n",
    "2. Design idempotent data transformations\n",
    "3. Write **assertions** to validate data quality programmatically\n",
    "4. Identify and handle common real-world data problems (dates, types, nulls)\n",
    "5. Apply the **pipeline pattern** to a real dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f29c73",
   "metadata": {},
   "source": [
    "## 1. Why Data Pipelines?\n",
    "\n",
    "### The Problem: One-Off Analysis Doesn't Scale\n",
    "\n",
    "**You've hit the wall when:**\n",
    "- Data updates regularly\n",
    "- Multiple people need consistent results\n",
    "- Stakeholders ask \"how did you get this number?\"\n",
    "- Requirements change\n",
    "\n",
    "**The solution:** A systematic, repeatable pipeline.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cd9118",
   "metadata": {},
   "source": [
    "## 2. The Bronze-Silver-Gold Pattern\n",
    "\n",
    "> **\"Preserve the original, clean incrementally, aggregate deliberately.\"**\n",
    "\n",
    "#### **Bronze Layer: Raw Ingestion**\n",
    "- Preserve original data exactly as received\n",
    "- No transformations\n",
    "- Keep everythingâ€”even if it looks wrong\n",
    "\n",
    "#### **Silver Layer: Clean & Validated**\n",
    "- Analysis-ready data\n",
    "- Fix types, handle nulls, validate\n",
    "- Document what was fixed\n",
    "\n",
    "#### **Gold Layer: Business Metrics**\n",
    "- Aggregated, joined, ready for reporting\n",
    "- Pre-computed KPIs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5cc2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T16:45:20.080948Z",
     "iopub.status.busy": "2025-10-20T16:45:20.080763Z",
     "iopub.status.idle": "2025-10-20T16:45:20.343375Z",
     "shell.execute_reply": "2025-10-20T16:45:20.342778Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "con = duckdb.connect(':memory:')\n",
    "print(\"âœ… Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b373f482",
   "metadata": {},
   "source": [
    "### Bronze Layer: Raw Ingestion\n",
    "\n",
    "**Goal:** Load data exactly as received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c7f6bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T16:45:20.345509Z",
     "iopub.status.busy": "2025-10-20T16:45:20.345290Z",
     "iopub.status.idle": "2025-10-20T16:45:20.435240Z",
     "shell.execute_reply": "2025-10-20T16:45:20.434986Z"
    }
   },
   "outputs": [],
   "source": [
    "# BRONZE: Load raw data\n",
    "print(\"=== BRONZE LAYER ===\\n\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE bronze_orders AS\n",
    "    SELECT * FROM '../../data/day3/teaching/olist_orders_subset.csv'\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE bronze_customers AS\n",
    "    SELECT * FROM '../../data/day3/teaching/olist_customers_subset.csv'\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE bronze_order_items AS\n",
    "    SELECT * FROM '../../data/day3/teaching/olist_order_items_subset.csv'\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Loaded {con.execute('SELECT COUNT(*) FROM bronze_orders').fetchone()[0]} orders\")\n",
    "print(\"âœ… Bronze layer complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51983f",
   "metadata": {},
   "source": [
    "### Silver Layer: Clean & Validate\n",
    "\n",
    "**Goal:** Transform into analysis-ready format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3db3e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T16:45:20.436244Z",
     "iopub.status.busy": "2025-10-20T16:45:20.436175Z",
     "iopub.status.idle": "2025-10-20T16:45:20.438769Z",
     "shell.execute_reply": "2025-10-20T16:45:20.438557Z"
    }
   },
   "outputs": [],
   "source": [
    "# SILVER: Clean and validate\n",
    "print(\"=== SILVER LAYER ===\\n\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE silver_orders AS\n",
    "    SELECT\n",
    "        order_id,\n",
    "        customer_id,\n",
    "        order_status,\n",
    "        TRY_CAST(order_purchase_timestamp AS TIMESTAMP) as order_date\n",
    "    FROM bronze_orders\n",
    "    WHERE order_id IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE silver_order_items AS\n",
    "    SELECT\n",
    "        order_id,\n",
    "        product_id,\n",
    "        CAST(price AS DOUBLE) as price,\n",
    "        CAST(freight_value AS DOUBLE) as freight\n",
    "    FROM bronze_order_items\n",
    "    WHERE order_id IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Created {con.execute('SELECT COUNT(*) FROM silver_orders').fetchone()[0]} clean orders\")\n",
    "print(\"âœ… Silver layer complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64811321",
   "metadata": {},
   "source": [
    "### Validation: Prove Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c55a1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T16:45:20.439786Z",
     "iopub.status.busy": "2025-10-20T16:45:20.439715Z",
     "iopub.status.idle": "2025-10-20T16:45:20.443430Z",
     "shell.execute_reply": "2025-10-20T16:45:20.443222Z"
    }
   },
   "outputs": [],
   "source": [
    "# VALIDATION\n",
    "print(\"=== VALIDATION ===\\n\")\n",
    "\n",
    "# Check 1: Primary key uniqueness\n",
    "order_count = con.execute(\"SELECT COUNT(*) FROM silver_orders\").fetchone()[0]\n",
    "order_unique = con.execute(\"SELECT COUNT(DISTINCT order_id) FROM silver_orders\").fetchone()[0]\n",
    "\n",
    "print(f\"âœ“ Order IDs unique? {order_count == order_unique}\")\n",
    "assert order_count == order_unique, \"Duplicate order IDs!\"\n",
    "\n",
    "# Check 2: No null critical fields\n",
    "null_ids = con.execute(\"SELECT COUNT(*) FROM silver_orders WHERE order_id IS NULL\").fetchone()[0]\n",
    "print(f\"âœ“ No NULL order IDs? {null_ids == 0}\")\n",
    "assert null_ids == 0, \"NULL order IDs found!\"\n",
    "\n",
    "# Check 3: Foreign key integrity\n",
    "orphans = con.execute(\"\"\"\n",
    "    SELECT COUNT(*)\n",
    "    FROM silver_order_items i\n",
    "    LEFT JOIN silver_orders o ON i.order_id = o.order_id\n",
    "    WHERE o.order_id IS NULL\n",
    "\"\"\").fetchone()[0]\n",
    "\n",
    "print(f\"âœ“ All items have valid orders? {orphans == 0}\")\n",
    "assert orphans == 0, \"Orphaned items found!\"\n",
    "\n",
    "print(\"\\nâœ… ALL VALIDATIONS PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3225daa",
   "metadata": {},
   "source": [
    "### Gold Layer: Business Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23da5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-20T16:45:20.444503Z",
     "iopub.status.busy": "2025-10-20T16:45:20.444444Z",
     "iopub.status.idle": "2025-10-20T16:45:20.450727Z",
     "shell.execute_reply": "2025-10-20T16:45:20.450529Z"
    }
   },
   "outputs": [],
   "source": [
    "# GOLD: Business metrics\n",
    "print(\"=== GOLD LAYER ===\\n\")\n",
    "\n",
    "con.execute(\"\"\"\n",
    "    CREATE TABLE gold_daily_sales AS\n",
    "    SELECT\n",
    "        CAST(o.order_date AS DATE) as date,\n",
    "        COUNT(DISTINCT o.order_id) as num_orders,\n",
    "        SUM(i.price + i.freight) as total_revenue\n",
    "    FROM silver_orders o\n",
    "    INNER JOIN silver_order_items i ON o.order_id = i.order_id\n",
    "    WHERE o.order_date IS NOT NULL\n",
    "    GROUP BY CAST(o.order_date AS DATE)\n",
    "    ORDER BY date\n",
    "\"\"\")\n",
    "\n",
    "result = con.execute(\"SELECT * FROM gold_daily_sales LIMIT 5\").df()\n",
    "print(\"Daily sales summary:\")\n",
    "display(result)\n",
    "print(\"\\nâœ… Gold layer complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b660fab9",
   "metadata": {},
   "source": [
    "## 3. Key Principles\n",
    "\n",
    "### 1. Idempotency\n",
    "> **\"Running the pipeline twice gives the same result.\"**\n",
    "\n",
    "**Good:** Recreate tables from scratch\n",
    "```python\n",
    "con.execute(\"DROP TABLE IF EXISTS gold_daily_sales\")\n",
    "con.execute(\"CREATE TABLE gold_daily_sales AS SELECT ...\")\n",
    "```\n",
    "\n",
    "### 2. Fail Fast\n",
    "> **\"If data is bad, stop immediately with a clear error.\"**\n",
    "\n",
    "**Good:**  \n",
    "```python\n",
    "assert df['price'].min() >= 0, \"Negative prices found!\"\n",
    "```\n",
    "\n",
    "### 3. Document Assumptions\n",
    "\n",
    "Every validation is documentation:\n",
    "```python\n",
    "assert df['order_id'].is_unique, \"Duplicate order IDs\"\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ac77c",
   "metadata": {},
   "source": [
    "## 4. Real-World Data Issues\n",
    "\n",
    "### Dates\n",
    "- Always parse explicitly with TRY_CAST or pd.to_datetime()\n",
    "- Standardize format (prefer ISO: YYYY-MM-DD)\n",
    "- Validate date ranges\n",
    "\n",
    "### Types\n",
    "- Check df.dtypes or INFORMATION_SCHEMA after loading\n",
    "- Numbers stored as strings? Clean then convert\n",
    "- Use TRY_CAST to handle errors gracefully\n",
    "\n",
    "### NULLs\n",
    "- Understand what NULL means (not applicable? unknown? not yet?)\n",
    "- Document your handling strategy\n",
    "- Remember: aggregations exclude NULLs\n",
    "\n",
    "### SQL vs Python\n",
    "**Use SQL for:** filtering, joining, grouping, sorting\n",
    "**Use Python for:** complex string manipulation, APIs, ML, visualization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81905ecb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Pipeline pattern:** Bronze (raw) â†’ Silver (clean) â†’ Gold (metrics)\n",
    "2. **Validations:** Assertions catch problems early and loudly\n",
    "3. **Idempotency:** Re-running gives same result\n",
    "4. **Dates, types, NULLs:** Check and validate early\n",
    "5. **Work habits:** Restart & Run All, small commits, read docs\n",
    "\n",
    "**You're not just analyzing dataâ€”you're building infrastructure.**\n",
    "\n",
    "---\n",
    "\n",
    "## Next: In-Class Exercise\n",
    "\n",
    "Build a mini-pipeline:\n",
    "1. Bronze: Load raw data\n",
    "2. Silver: Clean, validate (2 assertions)\n",
    "3. Gold: Create 2-3 metrics\n",
    "4. Document: Risk note\n",
    "\n",
    "**Time:** 15 minutes\n",
    "**Notebook:** `day3_exercise_mini_pipeline.ipynb`\n",
    "\n",
    "**Let's build!** ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
