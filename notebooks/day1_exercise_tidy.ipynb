{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 Exercise: Cleaning Messy Cafe Sales Data\n",
    "\n",
    "**Name:** _[Your name here]_  \n",
    "**Date:** October 8, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Transform a messy cafe sales dataset into a tidy format, designate and validate a primary key, and create summary tables.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "**File:** `../data/day1/dirty_cafe_sales.csv`  \n",
    "**Rows:** 10,000 cafe transactions  \n",
    "**Data Dictionary:** See `../data/day1/README.md`\n",
    "\n",
    "## Deliverable\n",
    "\n",
    "This notebook should **\"Restart & Run All\"** successfully when you're done!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Data Loading\n",
    "\n",
    "### TODO 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import pandas and numpy\n",
    "# Also import warnings to suppress FutureWarnings for cleaner output\n",
    "# Your code here:\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the dirty cafe sales data from ../data/day1/dirty_cafe_sales.csv\n",
    "# Hint: Use relative path from the notebooks/ directory\n",
    "# df = pd.read_csv(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Initial Exploration\n",
    "\n",
    "Before cleaning, let's understand what we have.\n",
    "\n",
    "### TODO 3: Display basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the shape of the dataframe\n",
    "# print(f\"Dataset shape: ...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display the first 10 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display column names and types\n",
    "# print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 4: Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Count missing values (NaN) in each column\n",
    "# print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 5: Check for sentinel values\n",
    "\n",
    "Look for \"ERROR\" and \"UNKNOWN\" in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Count \"ERROR\" values in each column\n",
    "# Hint: (df == 'ERROR').sum() counts ERROR across all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Count \"UNKNOWN\" values in each column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection: What Issues Did You Find?\n",
    "\n",
    "**TODO:** Write 2-3 sentences describing the data quality issues you observed.\n",
    "\n",
    "_[Your reflection here]_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Is This Data Tidy?\n",
    "\n",
    "### TODO 6: Evaluate against tidy data principles\n",
    "\n",
    "**The Three Rules:**\n",
    "1. Each variable is a column\n",
    "2. Each observation is a row\n",
    "3. Each value is a cell\n",
    "\n",
    "**Questions to answer in markdown:**\n",
    "\n",
    "1. What is the unit of observation in this dataset? (What does each row represent?)\n",
    "\n",
    "_[Your answer]_\n",
    "\n",
    "2. Does each variable have its own column?\n",
    "\n",
    "_[Your answer]_\n",
    "\n",
    "3. Is this dataset tidy? Why or why not?\n",
    "\n",
    "_[Your answer]_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Identify and Validate Primary Key\n",
    "\n",
    "### TODO 7: Identify the primary key candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check if 'Transaction ID' is unique\n",
    "# Hint: df['Transaction ID'].is_unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check for any NULL values in 'Transaction ID'\n",
    "# Hint: df['Transaction ID'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: If there are duplicates, find them\n",
    "# duplicates = df[df.duplicated(subset=['Transaction ID'], keep=False)]\n",
    "# print(duplicates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 8: Write validation assertions\n",
    "\n",
    "Once you've confirmed (or fixed) the primary key, write assertions to prove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add assertions to validate primary key\n",
    "# assert df['Transaction ID'].is_unique, \"Duplicate transaction IDs found\"\n",
    "# assert df['Transaction ID'].notna().all(), \"NULL transaction IDs found\"\n",
    "# print(\"✅ Transaction ID is a valid primary key\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection: Primary Key\n",
    "\n",
    "**TODO:** Explain what you found and any decisions you made.\n",
    "\n",
    "_[Your reflection here: Is Transaction ID a good primary key? Did you find any issues? How did you handle them?]_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Handle Missing Values\n",
    "\n",
    "### TODO 9: Standardize missing value representations\n",
    "\n",
    "Convert \"ERROR\", \"UNKNOWN\", and empty strings to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace sentinel values with NaN\n",
    "# Hint: df = df.replace(['ERROR', 'UNKNOWN', ''], np.nan)\n",
    "# Or replace column by column for more control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check missing values again after standardization\n",
    "# print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 10: Decide how to handle missing values\n",
    "\n",
    "**Options:**\n",
    "- Drop rows with missing values in critical columns\n",
    "- Fill with default values\n",
    "- Keep as NaN (document impact on analysis)\n",
    "\n",
    "**Your strategy:**\n",
    "\n",
    "_[Write your strategy here. Example: \"I will keep NaN for Payment Method because it represents missing data at point of sale. These transactions will be excluded from payment method analysis but included in overall sales totals.\"]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement your missing value strategy\n",
    "# Example:\n",
    "# df = df.dropna(subset=['Transaction ID'])  # Drop if no ID\n",
    "# df['Payment Method'] = df['Payment Method'].fillna('Unknown')  # Or keep as NaN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Fix Type Issues\n",
    "\n",
    "### TODO 11: Convert Quantity to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert Quantity to integer\n",
    "# Hint: You may need to handle NaN first\n",
    "# df['Quantity'] = df['Quantity'].astype('Int64')  # Int64 allows NaN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 12: Convert prices to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert 'Price Per Unit' to float\n",
    "# Hint: May need to handle non-numeric values first\n",
    "# df['Price Per Unit'] = pd.to_numeric(df['Price Per Unit'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert 'Total Spent' to float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 13: Convert Transaction Date to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Parse Transaction Date as datetime\n",
    "# df['Transaction Date'] = pd.to_datetime(df['Transaction Date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 14: Verify types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display dtypes to verify conversions worked\n",
    "# print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 15: Write type assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add assertions to validate types\n",
    "# assert df['Quantity'].dtype in ['int64', 'Int64'], \"Quantity should be integer\"\n",
    "# assert df['Price Per Unit'].dtype == 'float64', \"Price should be float\"\n",
    "# assert df['Transaction Date'].dtype == 'datetime64[ns]', \"Date should be datetime\"\n",
    "# print(\"✅ All types are correct\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 7: Validate Data Integrity\n",
    "\n",
    "### TODO 16: Check if Total Spent = Quantity × Price Per Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate expected total\n",
    "# df['Calculated Total'] = df['Quantity'] * df['Price Per Unit']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare with actual Total Spent (use np.isclose for float comparison)\n",
    "# mask = df['Total Spent'].notna() & df['Calculated Total'].notna()\n",
    "# mismatches = ~np.isclose(df.loc[mask, 'Total Spent'], df.loc[mask, 'Calculated Total'])\n",
    "# print(f\"Mismatches found: {mismatches.sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 17: Check for impossible values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check for negative or zero prices\n",
    "# Hint: df[df['Price Per Unit'] <= 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Check for zero or negative quantities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection: Data Integrity\n",
    "\n",
    "**TODO:** What did you find? How did you handle integrity issues?\n",
    "\n",
    "_[Your reflection here]_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Create Summary Tables\n",
    "\n",
    "Now that data is clean, answer some business questions!\n",
    "\n",
    "### TODO 18: Total sales by payment method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate total revenue and transaction count by payment method\n",
    "# Hint: df.groupby('Payment Method').agg({'Total Spent': ['sum', 'count'], ...})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 19: Most popular items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find most popular items by quantity sold\n",
    "# Hint: df.groupby('Item')['Quantity'].sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find highest revenue items\n",
    "# Hint: df.groupby('Item')['Total Spent'].sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 20: Location comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare transaction volume and average transaction value by location\n",
    "# df.groupby('Location').agg({\n",
    "#     'Transaction ID': 'count',\n",
    "#     'Total Spent': ['sum', 'mean']\n",
    "# })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 9: Final Validation\n",
    "\n",
    "### TODO 21: Run all validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Gather all your assertions in one cell to prove data quality\n",
    "\n",
    "print(\"Running final validation...\\n\")\n",
    "\n",
    "# Primary key\n",
    "# assert df['Transaction ID'].is_unique, \"Duplicate transaction IDs\"\n",
    "# assert df['Transaction ID'].notna().all(), \"NULL transaction IDs\"\n",
    "# print(\"✅ Primary key validated\")\n",
    "\n",
    "# Types\n",
    "# assert df['Quantity'].dtype in ['int64', 'Int64'], \"Quantity type wrong\"\n",
    "# assert df['Price Per Unit'].dtype == 'float64', \"Price type wrong\"\n",
    "# assert df['Transaction Date'].dtype == 'datetime64[ns]', \"Date type wrong\"\n",
    "# print(\"✅ Types validated\")\n",
    "\n",
    "# Data ranges (adjust based on your data)\n",
    "# assert (df['Quantity'] > 0).all(), \"Invalid quantities found\"\n",
    "# assert (df['Price Per Unit'] > 0).all(), \"Invalid prices found\"\n",
    "# print(\"✅ Data ranges validated\")\n",
    "\n",
    "# print(\"\\n✅ All validations passed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 10: Documentation\n",
    "\n",
    "### TODO 22: Document your data cleaning process\n",
    "\n",
    "Write a brief summary (8-10 sentences) of:\n",
    "1. What problems you found\n",
    "2. What decisions you made\n",
    "3. What the implications are for analysis\n",
    "4. What a stakeholder should know about this data\n",
    "\n",
    "---\n",
    "\n",
    "## Data Cleaning Summary\n",
    "\n",
    "_[Your summary here]_\n",
    "\n",
    "### Issues Found\n",
    "- _[List major issues]_\n",
    "\n",
    "### Actions Taken\n",
    "- _[List your cleaning steps]_\n",
    "\n",
    "### Assumptions Made\n",
    "- _[List key assumptions]_\n",
    "\n",
    "### Implications for Analysis\n",
    "- _[What should analysts know?]_\n",
    "\n",
    "### Data Quality Assessment\n",
    "- _[Overall, how clean is this data now? What percentage is usable?]_\n",
    "\n",
    "---\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "You've successfully cleaned a real messy dataset using tidy data principles!\n",
    "\n",
    "**Final check:** Can you **\"Restart & Run All\"** successfully? That's the gold standard!\n",
    "\n",
    "**Reflection:** What was the hardest part? What did you learn?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
